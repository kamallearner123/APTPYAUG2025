{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b3dcd21",
   "metadata": {},
   "source": [
    "# Assignment 5 — Mini Project: Model Selection & Reproducible Report\n",
    "*Prepared:* 2025-10-11\n",
    "\n",
    "**Goal:** Choose a dataset; compare 2–3 algorithms; produce a concise executive summary with evidence.\n",
    "\n",
    "**Pick one dataset:** digits | breast_cancer | wine | diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc14e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits, load_breast_cancer, load_wine, load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, roc_curve,\n",
    "                             confusion_matrix, mean_absolute_error, mean_squared_error, r2_score)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "plt.rcParams['figure.figsize'] = (7,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose dataset here:\n",
    "task = 'classification'  # 'classification' or 'regression'\n",
    "dataset_name = 'breast_cancer'  # 'digits' | 'breast_cancer' | 'wine' | 'diabetes'\n",
    "\n",
    "def load_dataset(name):\n",
    "    if name == 'digits':\n",
    "        d = load_digits(); return d.data, d.target, 'classification'\n",
    "    if name == 'breast_cancer':\n",
    "        d = load_breast_cancer(); return d.data, d.target, 'classification'\n",
    "    if name == 'wine':\n",
    "        d = load_wine(); return d.data, d.target, 'classification'\n",
    "    if name == 'diabetes':\n",
    "        d = load_diabetes(); return d.data, d.target, 'regression'\n",
    "    raise ValueError('unknown dataset')\n",
    "\n",
    "X, y, inferred = load_dataset(dataset_name)\n",
    "task = inferred\n",
    "print('Task:', task, ' Dataset:', dataset_name, ' X shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139fe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA — a couple of simple plots\n",
    "if dataset_name == 'digits':\n",
    "    from sklearn.datasets import load_digits\n",
    "    d = load_digits()\n",
    "    fig, axes = plt.subplots(2,4, figsize=(8,4))\n",
    "    for ax, img, label in zip(axes.ravel(), d.images[:8], d.target[:8]):\n",
    "        ax.imshow(img, cmap='gray'); ax.set_title(f'Label: {label}'); ax.axis('off')\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    df = pd.DataFrame(X)\n",
    "    df.hist(bins=20, figsize=(10,6)); plt.suptitle('Feature Histograms'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e5ef1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "strat = y if task=='classification' else None\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=strat, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf69036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define candidate models\n",
    "candidates = []\n",
    "if task == 'classification':\n",
    "    candidates = [\n",
    "        ('LogReg', Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression(max_iter=1000, random_state=RANDOM_STATE))])),\n",
    "        ('Tree', DecisionTreeClassifier(random_state=RANDOM_STATE)),\n",
    "        ('kNN', Pipeline([('scaler', StandardScaler()), ('clf', KNeighborsClassifier(n_neighbors=5))]))\n",
    "    ]\n",
    "else:\n",
    "    candidates = [\n",
    "        ('Linear', Pipeline([('scaler', StandardScaler()), ('reg', LinearRegression())])),\n",
    "        ('Ridge', Pipeline([('scaler', StandardScaler()), ('reg', Ridge(alpha=1.0, random_state=RANDOM_STATE))])),\n",
    "        ('kNN_Reg', Pipeline([('scaler', StandardScaler()), ('reg', KNeighborsRegressor(n_neighbors=7))]))\n",
    "    ]\n",
    "\n",
    "# Evaluate candidates\n",
    "rows = []\n",
    "for name, model in candidates:\n",
    "    model.fit(X_train, y_train)\n",
    "    if task == 'classification':\n",
    "        pred = model.predict(X_test)\n",
    "        proba = None\n",
    "        try:\n",
    "            from sklearn.base import is_classifier\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                proba = model.predict_proba(X_test)\n",
    "        except Exception:\n",
    "            proba = None\n",
    "        row = dict(Model=name,\n",
    "                   Acc=accuracy_score(y_test, pred),\n",
    "                   F1=f1_score(y_test, pred, average='weighted'),\n",
    "                   Prec=precision_score(y_test, pred, average='weighted', zero_division=0),\n",
    "                   Rec=recall_score(y_test, pred, average='weighted'))\n",
    "        rows.append(row)\n",
    "    else:\n",
    "        pred = model.predict(X_test)\n",
    "        row = dict(Model=name,\n",
    "                   MAE=mean_absolute_error(y_test, pred),\n",
    "                   RMSE=mean_squared_error(y_test, pred, squared=False),\n",
    "                   R2=r2_score(y_test, pred))\n",
    "        rows.append(row)\n",
    "\n",
    "metrics_df = pd.DataFrame(rows).set_index('Model')\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple matplotlib table of metrics\n",
    "fig, ax = plt.subplots(figsize=(6, 0.5 + 0.4*len(metrics_df)))\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=np.round(metrics_df.values, 4),\n",
    "                 rowLabels=metrics_df.index,\n",
    "                 colLabels=metrics_df.columns,\n",
    "                 loc='center')\n",
    "table.auto_set_font_size(False); table.set_fontsize(10)\n",
    "table.scale(1, 1.2)\n",
    "plt.title('Model Comparison'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592de88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics per best model\n",
    "best_name = metrics_df.sort_values(metrics_df.columns[-1], ascending=False).index[0]  # crude pick\n",
    "best_model = dict(candidates)[best_name]\n",
    "best_model.fit(X_train, y_train)\n",
    "pred = best_model.predict(X_test)\n",
    "\n",
    "if task == 'classification':\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    print('Best model:', best_name, '\\nConfusion matrix:\\n', cm)\n",
    "    # ROC/PR optional if predict_proba exists and binary\n",
    "else:\n",
    "    plt.scatter(pred, y_test - pred, s=18)\n",
    "    plt.axhline(0, linestyle='--')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Residual'); plt.title(f'Residuals — {best_name}'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0595f1ee",
   "metadata": {},
   "source": [
    "**TODOs:**\n",
    "- Add one robustness check (bootstrap CI or repeated splits) and a 6–10 bullet executive summary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}