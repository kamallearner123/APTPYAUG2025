{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e6b53c",
   "metadata": {},
   "source": [
    "# Assignment 1 — Linear Regression with Polynomial Features & Ridge (Diabetes)\n",
    "*Prepared:* 2025-10-11\n",
    "\n",
    "**Goal:** Predict diabetes progression; compare plain Linear Regression vs PolynomialFeatures+Ridge; include a simple bootstrap CI for RMSE.\n",
    "\n",
    "**Datasets:** `sklearn.datasets.load_diabetes()`\n",
    "\n",
    "**Tools:** pandas, matplotlib, scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d5ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "plt.rcParams['figure.figsize'] = (7,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f38fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset into a DataFrame\n",
    "data = load_diabetes()\n",
    "X, y = data.data, data.target\n",
    "df = pd.DataFrame(X, columns=data.feature_names).assign(target=y)\n",
    "display(df.head())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d17df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (matplotlib imshow)\n",
    "corr = df.corr(numeric_only=True)\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(corr, interpolation='nearest')\n",
    "ax.set_title('Correlation Heatmap')\n",
    "ax.set_xticks(range(len(corr.columns))); ax.set_xticklabels(corr.columns, rotation=90)\n",
    "ax.set_yticks(range(len(corr.index))); ax.set_yticklabels(corr.index)\n",
    "fig.colorbar(im, ax=ax); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f803097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline A: StandardScaler -> LinearRegression\n",
    "pipe_lr = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('lr', LinearRegression())])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# Pipeline B: StandardScaler -> PolynomialFeatures(deg=2) -> Ridge\n",
    "pipe_pr = Pipeline([('scaler', StandardScaler()),\n",
    "                    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "                    ('ridge', Ridge(alpha=1.0, random_state=RANDOM_STATE))])\n",
    "pipe_pr.fit(X_train, y_train)\n",
    "\n",
    "def eval_model(model, Xtr, ytr, Xte, yte):\n",
    "    pred_tr = model.predict(Xtr); pred_te = model.predict(Xte)\n",
    "    res = {\n",
    "        'MAE_tr': mean_absolute_error(ytr, pred_tr),\n",
    "        'RMSE_tr': mean_squared_error(ytr, pred_tr, squared=False),\n",
    "        'R2_tr': r2_score(ytr, pred_tr),\n",
    "        'MAE_te': mean_absolute_error(yte, pred_te),\n",
    "        'RMSE_te': mean_squared_error(yte, pred_te, squared=False),\n",
    "        'R2_te': r2_score(yte, pred_te),\n",
    "    }\n",
    "    return res\n",
    "\n",
    "res_lr = eval_model(pipe_lr, X_train, y_train, X_test, y_test)\n",
    "res_pr = eval_model(pipe_pr, X_train, y_train, X_test, y_test)\n",
    "pd.DataFrame([res_lr, res_pr], index=['Linear','Poly+Ridge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b81a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plots\n",
    "def residual_plot(model, X, y, title):\n",
    "    pred = model.predict(X)\n",
    "    resid = y - pred\n",
    "    plt.scatter(pred, resid, s=18)\n",
    "    plt.axhline(0, linestyle='--')\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Residual')\n",
    "    plt.title(title); plt.show()\n",
    "\n",
    "residual_plot(pipe_lr, X_test, y_test, 'Residuals — Linear Regression (test)')\n",
    "residual_plot(pipe_pr, X_test, y_test, 'Residuals — Poly+Ridge (test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8106d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap CI for RMSE (simple)\n",
    "def bootstrap_rmse(model, X, y, B=200, random_state=RANDOM_STATE):\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    rmses = []\n",
    "    n = len(y)\n",
    "    for _ in range(B):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        yb = y[idx]; Xb = X[idx]\n",
    "        pred = model.predict(Xb)\n",
    "        rmses.append(mean_squared_error(yb, pred, squared=False))\n",
    "    lower, upper = np.percentile(rmses, [2.5, 97.5])\n",
    "    return np.mean(rmses), (lower, upper)\n",
    "\n",
    "mean_rmse_lr, ci_lr = bootstrap_rmse(pipe_lr, X_test, y_test)\n",
    "mean_rmse_pr, ci_pr = bootstrap_rmse(pipe_pr, X_test, y_test)\n",
    "print('Linear RMSE bootstrap mean & 95% CI:', mean_rmse_lr, ci_lr)\n",
    "print('Poly+Ridge RMSE bootstrap mean & 95% CI:', mean_rmse_pr, ci_pr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a28945b",
   "metadata": {},
   "source": [
    "**TODOs:**\n",
    "- Add a scatter with best single feature vs target + fitted line.\n",
    "- Write 5–8 bullet insights comparing both models and CI results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}